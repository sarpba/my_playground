{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "gkaA5uq4-CkH",
        "vr7qT1sg-J3J",
        "TX9QFCJl_UC7",
        "gQF1cXb3zo8a",
        "1dgYf8KxLF8w"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ec4917e9f9448b29db7f84b9b5d5075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac7445acfad24011b043c7a424367be5",
              "IPY_MODEL_6848037984e9448cbdcaebecb2493c04",
              "IPY_MODEL_22a375fd3824410c8a2740360ec209ff",
              "IPY_MODEL_bd6a71f36b7d426e9b68e144ef019712"
            ],
            "layout": "IPY_MODEL_16e1063f8df04df0bcb4260a40da38a0"
          }
        },
        "3e6b4dd20c894c4bba3f986820a6a4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039d950e3cba449398520f8e4a0f99fd",
            "placeholder": "​",
            "style": "IPY_MODEL_5e185bdc66b74deb95fe8ed31acda22b",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3d6785fc68464fd6ae05edbea26328d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5e1c1ea3d2c44413a650237d83d8d45f",
            "placeholder": "​",
            "style": "IPY_MODEL_a9e94aa58faa430caadc04886c6fd769",
            "value": ""
          }
        },
        "55ab3a9a23994ae78b2b20709416dc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_1b43ff3bdfd74db3ad734349a0636757",
            "style": "IPY_MODEL_ff6dd88f4da349a3b3bd66f362ac4e7a",
            "value": true
          }
        },
        "997c8a1de89a4281b9584c66816f5217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dd64c3ba262f4d12952c53e01f631693",
            "style": "IPY_MODEL_26d04c7783f643adbf113fd0f00fba5d",
            "tooltip": ""
          }
        },
        "3538ccdea69e4e588237e8dcc7004cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ec2c53dc904024b76aad43d6970e24",
            "placeholder": "​",
            "style": "IPY_MODEL_e188e400ec39403f845275f0cebaa1a1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "16e1063f8df04df0bcb4260a40da38a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "039d950e3cba449398520f8e4a0f99fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e185bdc66b74deb95fe8ed31acda22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e1c1ea3d2c44413a650237d83d8d45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e94aa58faa430caadc04886c6fd769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b43ff3bdfd74db3ad734349a0636757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6dd88f4da349a3b3bd66f362ac4e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd64c3ba262f4d12952c53e01f631693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d04c7783f643adbf113fd0f00fba5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d9ec2c53dc904024b76aad43d6970e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e188e400ec39403f845275f0cebaa1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30f8c00e3b74deda69f1861f9fa148b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f962c79f6ded49a4841e2d134ad9a6b2",
            "placeholder": "​",
            "style": "IPY_MODEL_57543dcac74e44b1be6d4a51257907c2",
            "value": "Connecting..."
          }
        },
        "f962c79f6ded49a4841e2d134ad9a6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57543dcac74e44b1be6d4a51257907c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac7445acfad24011b043c7a424367be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e978080567da4a5cb3d1a9eabd8c0933",
            "placeholder": "​",
            "style": "IPY_MODEL_2cfab3f5eec54e6399ef8b2b1b8253f8",
            "value": "Token is valid (permission: write)."
          }
        },
        "6848037984e9448cbdcaebecb2493c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc619b385f444c9a8bacb0683f8ca27f",
            "placeholder": "​",
            "style": "IPY_MODEL_03fd80df25fe458aa0bc8889bfb60d62",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "22a375fd3824410c8a2740360ec209ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9561d2f9b79d46d79179b13c0192f85e",
            "placeholder": "​",
            "style": "IPY_MODEL_fc744cfc02774bd4b416c61e2037b9c8",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "bd6a71f36b7d426e9b68e144ef019712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9824a928cc4e46aaabe32ef2a36075ec",
            "placeholder": "​",
            "style": "IPY_MODEL_775d90460ae444849498b299730fab47",
            "value": "Login successful"
          }
        },
        "e978080567da4a5cb3d1a9eabd8c0933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfab3f5eec54e6399ef8b2b1b8253f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc619b385f444c9a8bacb0683f8ca27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03fd80df25fe458aa0bc8889bfb60d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9561d2f9b79d46d79179b13c0192f85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc744cfc02774bd4b416c61e2037b9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9824a928cc4e46aaabe32ef2a36075ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775d90460ae444849498b299730fab47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install datasets\n",
        "!pip install --upgrade accelerate\n",
        "!pip install --upgrade transformers torch\n",
        "!pip install --upgrade torchvision"
      ],
      "metadata": {
        "id": "RdVpFFFraJfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "LCpkLG1TP8F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "_K63_15xp2-Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "0ec4917e9f9448b29db7f84b9b5d5075",
            "3e6b4dd20c894c4bba3f986820a6a4fb",
            "3d6785fc68464fd6ae05edbea26328d7",
            "55ab3a9a23994ae78b2b20709416dc0d",
            "997c8a1de89a4281b9584c66816f5217",
            "3538ccdea69e4e588237e8dcc7004cd2",
            "16e1063f8df04df0bcb4260a40da38a0",
            "039d950e3cba449398520f8e4a0f99fd",
            "5e185bdc66b74deb95fe8ed31acda22b",
            "5e1c1ea3d2c44413a650237d83d8d45f",
            "a9e94aa58faa430caadc04886c6fd769",
            "1b43ff3bdfd74db3ad734349a0636757",
            "ff6dd88f4da349a3b3bd66f362ac4e7a",
            "dd64c3ba262f4d12952c53e01f631693",
            "26d04c7783f643adbf113fd0f00fba5d",
            "d9ec2c53dc904024b76aad43d6970e24",
            "e188e400ec39403f845275f0cebaa1a1",
            "e30f8c00e3b74deda69f1861f9fa148b",
            "f962c79f6ded49a4841e2d134ad9a6b2",
            "57543dcac74e44b1be6d4a51257907c2",
            "ac7445acfad24011b043c7a424367be5",
            "6848037984e9448cbdcaebecb2493c04",
            "22a375fd3824410c8a2740360ec209ff",
            "bd6a71f36b7d426e9b68e144ef019712",
            "e978080567da4a5cb3d1a9eabd8c0933",
            "2cfab3f5eec54e6399ef8b2b1b8253f8",
            "cc619b385f444c9a8bacb0683f8ca27f",
            "03fd80df25fe458aa0bc8889bfb60d62",
            "9561d2f9b79d46d79179b13c0192f85e",
            "fc744cfc02774bd4b416c61e2037b9c8",
            "9824a928cc4e46aaabe32ef2a36075ec",
            "775d90460ae444849498b299730fab47"
          ]
        },
        "outputId": "d5d99491-fd9e-4d94-9165-8c72bac3c18d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ec4917e9f9448b29db7f84b9b5d5075"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Adatkészlet betöltése\n",
        "dataset = load_dataset('Bazsalanszky/alpaca-cleaned-gemini-hun')\n",
        "\n",
        "# Modell betöltése és inicializálása\n",
        "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "w1rC7vwGN-TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I87vl9cmpxUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BFLOAT16"
      ],
      "metadata": {
        "id": "gkaA5uq4-CkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Analízis végrehajtása a LLM modellel\n",
        "def analyze_interaction(input_text, response_text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Egy segéd vagy, aki a user - assistant interakciót elemzi. Az aszisztant válasza mennyire felelt meg a felhaszálói kérésnek 1-10 közt. Csak egy számot írj, semmi mást!\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Felhasználói utasítás:\\n{input_text}\\nAssistant válasz:\\n{response_text}\"}\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(messages, max_new_tokens=10)\n",
        "    assistant_response = outputs[0]['generated_text'][-1]['content'].strip()\n",
        "    return assistant_response\n",
        "\n",
        "def add_analysis(example):\n",
        "    analysis = analyze_interaction(example['input'], example['response'])\n",
        "    example['analize'] = analysis\n",
        "    return example\n",
        "\n",
        "def process_chunk(chunk, chunk_id, num_chunks, chunk_dir):\n",
        "    print(f\"Processing chunk {chunk_id + 1}/{num_chunks}...\")\n",
        "    chunk = chunk.map(add_analysis)\n",
        "    chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "    with open(chunk_file, 'w', encoding='utf-8') as f:\n",
        "        for item in chunk:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    print(f\"Chunk {chunk_id} saved to {chunk_file}.\")\n",
        "    print(f\"Progress: {((chunk_id + 1) / num_chunks) * 100:.2f}%\")\n",
        "\n",
        "def get_last_processed_chunk(chunk_dir):\n",
        "    chunk_files = [f for f in os.listdir(chunk_dir) if f.startswith('chunk_') and f.endswith('.jsonl')]\n",
        "    if not chunk_files:\n",
        "        return -1\n",
        "    chunk_ids = [int(f.split('_')[1].split('.')[0]) for f in chunk_files]\n",
        "    return max(chunk_ids)\n",
        "\n",
        "# Ellenőrizzük az utolsó feldolgozott chunk-ot\n",
        "chunk_dir = 'chunks'\n",
        "if not os.path.exists(chunk_dir):\n",
        "    os.makedirs(chunk_dir)\n",
        "last_processed_chunk = get_last_processed_chunk(chunk_dir)\n",
        "\n",
        "# Adatok 1000 soros darabokra bontása és feldolgozása\n",
        "chunk_size = 1000\n",
        "num_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size\n",
        "\n",
        "# Összes feldolgozási idő mérése\n",
        "start_time = time.time()\n",
        "\n",
        "for chunk_id in range(last_processed_chunk + 1, num_chunks):\n",
        "    start_idx = chunk_id * chunk_size\n",
        "    end_idx = min(start_idx + chunk_size, len(dataset['train']))\n",
        "    chunk = dataset['train'].select(range(start_idx, end_idx))\n",
        "    process_chunk(chunk, chunk_id, num_chunks, chunk_dir)\n",
        "\n",
        "# Az összesített eredmények összegyűjtése\n",
        "def aggregate_results(num_chunks, chunk_dir):\n",
        "    all_data = []\n",
        "    for chunk_id in range(num_chunks):\n",
        "        chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "        if os.path.exists(chunk_file):\n",
        "            with open(chunk_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    all_data.append(json.loads(line))\n",
        "    return all_data\n",
        "\n",
        "all_results = aggregate_results(num_chunks, chunk_dir)\n",
        "\n",
        "# Összesített eredmények mentése\n",
        "with open('data_with_analysis.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in all_results:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"All chunks have been processed and aggregated in {total_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "id": "FInUJSfgXW0I",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLOAT16"
      ],
      "metadata": {
        "id": "vr7qT1sg-J3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Analízis végrehajtása a LLM modellel\n",
        "def analyze_interaction(input_text, response_text, instruction_text):\n",
        "    if input_text:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{input_text}\\n\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "    else:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Egy segéd vagy, aki a user - assistant interakciót elemzi. Az aszisztant válasza mennyire felelt meg a felhaszálói kérésnek 1-10 közt. Csak egy számot írj, semmi mást!\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(messages, max_new_tokens=10)\n",
        "    assistant_response = outputs[0]['generated_text'][-1]['content'].strip()\n",
        "    return assistant_response\n",
        "\n",
        "def add_analysis(example):\n",
        "    input_text = example['input']\n",
        "    instruction_text = example['instruction']\n",
        "    response_text = example['response']\n",
        "    analysis = analyze_interaction(input_text, response_text, instruction_text)\n",
        "    example['analize'] = analysis\n",
        "    return example\n",
        "\n",
        "def process_chunk(chunk, chunk_id, num_chunks, chunk_dir):\n",
        "    print(f\"Processing chunk {chunk_id + 1}/{num_chunks}...\")\n",
        "    chunk = chunk.map(add_analysis)\n",
        "    chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "    with open(chunk_file, 'w', encoding='utf-8') as f:\n",
        "        for item in chunk:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    print(f\"Chunk {chunk_id} saved to {chunk_file}.\")\n",
        "    print(f\"Progress: {((chunk_id + 1) / num_chunks) * 100:.2f}%\")\n",
        "\n",
        "def get_last_processed_chunk(chunk_dir):\n",
        "    chunk_files = [f for f in os.listdir(chunk_dir) if f.startswith('chunk_') and f.endswith('.jsonl')]\n",
        "    if not chunk_files:\n",
        "        return -1\n",
        "    chunk_ids = [int(f.split('_')[1].split('.')[0]) for f in chunk_files]\n",
        "    return max(chunk_ids)\n",
        "\n",
        "# Ellenőrizzük az utolsó feldolgozott chunk-ot\n",
        "chunk_dir = 'chunks'\n",
        "if not os.path.exists(chunk_dir):\n",
        "    os.makedirs(chunk_dir)\n",
        "last_processed_chunk = get_last_processed_chunk(chunk_dir)\n",
        "\n",
        "# Adatok 1000 soros darabokra bontása és feldolgozása\n",
        "chunk_size = 1000\n",
        "num_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size\n",
        "\n",
        "# Összes feldolgozási idő mérése\n",
        "start_time = time.time()\n",
        "\n",
        "for chunk_id in range(last_processed_chunk + 1, num_chunks):\n",
        "    start_idx = chunk_id * chunk_size\n",
        "    end_idx = min(start_idx + chunk_size, len(dataset['train']))\n",
        "    chunk = dataset['train'].select(range(start_idx, end_idx))\n",
        "    process_chunk(chunk, chunk_id, num_chunks, chunk_dir)\n",
        "\n",
        "# Az összesített eredmények összegyűjtése\n",
        "def aggregate_results(num_chunks, chunk_dir):\n",
        "    all_data = []\n",
        "    for chunk_id in range(num_chunks):\n",
        "        chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "        if os.path.exists(chunk_file):\n",
        "            with open(chunk_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    all_data.append(json.loads(line))\n",
        "    return all_data\n",
        "\n",
        "all_results = aggregate_results(num_chunks, chunk_dir)\n",
        "\n",
        "# Összesített eredmények mentése\n",
        "with open('data_with_analysis.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in all_results:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"All chunks have been processed and aggregated in {total_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "id": "GgGHPdI-91BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLOAT16 faster"
      ],
      "metadata": {
        "id": "TX9QFCJl_UC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Analízis végrehajtása a LLM modellel\n",
        "def analyze_interaction(input_text, response_text, instruction_text):\n",
        "    if input_text:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{input_text}\\n\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "    else:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Egy segéd vagy, aki a user - assistant interakciót elemzi. Az aszisztant válasza mennyire felelt meg a felhaszálói kérésnek vagy kérdésnek 1-10 közt. Gondold át, légy alapos. Csak egy számot írj, semmi mást!\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(messages, max_new_tokens=10)\n",
        "    assistant_response = outputs[0]['generated_text'][-1]['content'].strip()\n",
        "    return assistant_response\n",
        "\n",
        "def add_analysis(example):\n",
        "    input_text = example['input']\n",
        "    instruction_text = example['instruction']\n",
        "    response_text = example['response']\n",
        "    analysis = analyze_interaction(input_text, response_text, instruction_text)\n",
        "    example['analize'] = analysis\n",
        "    return example\n",
        "\n",
        "def process_chunk(chunk, chunk_id, num_chunks, chunk_dir):\n",
        "    print(f\"Processing chunk {chunk_id + 1}/{num_chunks}...\")\n",
        "    chunk = chunk.map(add_analysis)\n",
        "    chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "    with open(chunk_file, 'w', encoding='utf-8') as f:\n",
        "        for item in chunk:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    print(f\"Chunk {chunk_id} saved to {chunk_file}.\")\n",
        "    print(f\"Progress: {((chunk_id + 1) / num_chunks) * 100:.2f}%\")\n",
        "\n",
        "def get_last_processed_chunk(chunk_dir):\n",
        "    chunk_files = [f for f in os.listdir(chunk_dir) if f.startswith('chunk_') and f.endswith('.jsonl')]\n",
        "    if not chunk_files:\n",
        "        return -1\n",
        "    chunk_ids = [int(f.split('_')[1].split('.')[0]) for f in chunk_files]\n",
        "    return max(chunk_ids)\n",
        "\n",
        "# Ellenőrizzük az utolsó feldolgozott chunk-ot\n",
        "chunk_dir = 'chunks'\n",
        "if not os.path.exists(chunk_dir):\n",
        "    os.makedirs(chunk_dir)\n",
        "last_processed_chunk = get_last_processed_chunk(chunk_dir)\n",
        "\n",
        "# Adatok 1000 soros darabokra bontása és feldolgozása\n",
        "chunk_size = 1000\n",
        "num_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size\n",
        "\n",
        "# Összes feldolgozási idő mérése\n",
        "start_time = time.time()\n",
        "\n",
        "for chunk_id in range(last_processed_chunk + 1, num_chunks):\n",
        "    start_idx = chunk_id * chunk_size\n",
        "    end_idx = min(start_idx + chunk_size, len(dataset['train']))\n",
        "    chunk = dataset['train'].select(range(start_idx, end_idx))\n",
        "    process_chunk(chunk, chunk_id, num_chunks, chunk_dir)\n",
        "\n",
        "# Az összesített eredmények összegyűjtése\n",
        "def aggregate_results(num_chunks, chunk_dir):\n",
        "    all_data = []\n",
        "    for chunk_id in range(num_chunks):\n",
        "        chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "        if os.path.exists(chunk_file):\n",
        "            with open(chunk_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    all_data.append(json.loads(line))\n",
        "    return all_data\n",
        "\n",
        "all_results = aggregate_results(num_chunks, chunk_dir)\n",
        "\n",
        "# Összesített eredmények mentése\n",
        "with open('data_with_analysis.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in all_results:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"All chunks have been processed and aggregated in {total_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "id": "oYCXlwwZmMyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INT8"
      ],
      "metadata": {
        "id": "hjiPG98ut_op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Tokenizer betöltése\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Modell betöltése és kvantálása\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    load_in_8bit=True,  # INT8 kvantálás engedélyezése\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Analízis végrehajtása a LLM modellel\n",
        "def analyze_interaction(input_text, response_text, instruction_text):\n",
        "    if input_text:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{input_text}\\n\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "    else:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Egy segéd vagy, aki a user - assistant interakciót elemzi. Az aszisztant válasza mennyire felelt meg a felhaszálói kérésnek vagy kérdésnek 1-10 közt. Gondold át, légy alapos. Csak egy számot írj, semmi mást!\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(messages, max_new_tokens=10)\n",
        "    assistant_response = outputs[0]['generated_text'][-1]['content'].strip()\n",
        "    return assistant_response\n",
        "\n",
        "def add_analysis(example):\n",
        "    input_text = example['input']\n",
        "    instruction_text = example['instruction']\n",
        "    response_text = example['response']\n",
        "    analysis = analyze_interaction(input_text, response_text, instruction_text)\n",
        "    example['analize'] = analysis\n",
        "    return example\n",
        "\n",
        "def process_chunk(chunk, chunk_id, num_chunks, chunk_dir):\n",
        "    print(f\"Processing chunk {chunk_id + 1}/{num_chunks}...\")\n",
        "    chunk = chunk.map(add_analysis)\n",
        "    chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "    with open(chunk_file, 'w', encoding='utf-8') as f:\n",
        "        for item in chunk:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    print(f\"Chunk {chunk_id} saved to {chunk_file}.\")\n",
        "    print(f\"Progress: {((chunk_id + 1) / num_chunks) * 100:.2f}%\")\n",
        "\n",
        "def get_last_processed_chunk(chunk_dir):\n",
        "    chunk_files = [f for f in os.listdir(chunk_dir) if f.startswith('chunk_') and f.endswith('.jsonl')]\n",
        "    if not chunk_files:\n",
        "        return -1\n",
        "    chunk_ids = [int(f.split('_')[1].split('.')[0]) for f in chunk_files]\n",
        "    return max(chunk_ids)\n",
        "\n",
        "# Ellenőrizzük az utolsó feldolgozott chunk-ot\n",
        "chunk_dir = 'chunks'\n",
        "if not os.path.exists(chunk_dir):\n",
        "    os.makedirs(chunk_dir)\n",
        "last_processed_chunk = get_last_processed_chunk(chunk_dir)\n",
        "\n",
        "# Adatok 1000 soros darabokra bontása és feldolgozása\n",
        "chunk_size = 1000\n",
        "num_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size\n",
        "\n",
        "# Összes feldolgozási idő mérése\n",
        "start_time = time.time()\n",
        "\n",
        "for chunk_id in range(last_processed_chunk + 1, num_chunks):\n",
        "    start_idx = chunk_id * chunk_size\n",
        "    end_idx = min(start_idx + chunk_size, len(dataset['train']))\n",
        "    chunk = dataset['train'].select(range(start_idx, end_idx))\n",
        "    process_chunk(chunk, chunk_id, num_chunks, chunk_dir)\n",
        "\n",
        "# Az összesített eredmények összegyűjtése\n",
        "def aggregate_results(num_chunks, chunk_dir):\n",
        "    all_data = []\n",
        "    for chunk_id in range(num_chunks):\n",
        "        chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "        if os.path.exists(chunk_file):\n",
        "            with open(chunk_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    all_data.append(json.loads(line))\n",
        "    return all_data\n",
        "\n",
        "all_results = aggregate_results(num_chunks, chunk_dir)\n",
        "\n",
        "# Összesített eredmények mentése\n",
        "with open('data_with_analysis.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in all_results:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"All chunks have been processed and aggregated in {total_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "0XzKLpSct9tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GGUF (not working)"
      ],
      "metadata": {
        "id": "gQF1cXb3zo8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true"
      ],
      "metadata": {
        "id": "DNn1fPto0ck8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python\n",
        "\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "zLYEW6zHBQNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FTe6b7xF1L_",
        "outputId": "49990173-67ac-4f3b-c04d-804e162b884f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "5Wjd_Q_oFw4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!set LLAMA_CUBLAS=1\n",
        "!set CMAKE_ARGS=-DLLAMA_CUBLAS=on\n",
        "!set FORCE_CMAKE=1\n",
        "!python -m pip install llama-cpp-python==0.2.83 --prefer-binary --extra-index-url=https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/wheels/llama_cpp_python_ggml-0.1.78+cu122-cp310-cp310-linux_x86_64.whl\n",
        "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "Iiekeszv0woG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r gpu_requirements.txt"
      ],
      "metadata": {
        "id": "lrQLJznBDw_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall  llama-cpp-python \\\n",
        "  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122"
      ],
      "metadata": {
        "id": "-8WND7JXHf5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Modell betöltése és inicializálása gguf Q4_M kvantálással\n",
        "model_path = \"/content/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\"\n",
        "\n",
        "\n",
        "llm = Llama(model_path=model_path, n_gpu_layers=-1)\n",
        "\n",
        "# Analízis végrehajtása a LLM modellel\n",
        "def analyze_interaction(input_text, response_text, instruction_text):\n",
        "    if input_text:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{input_text}\\n\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "    else:\n",
        "        prompt = f\"Felhasználói utasítás:\\n{instruction_text}\\nAssistant válasz:\\n{response_text}\"\n",
        "\n",
        "    full_prompt = f\"Egy segéd vagy, aki a user - assistant interakciót elemzi. Az asszisztant válasza mennyire felelt meg a felhaszálói kérésnek, kérdésnek 1-10 közt. Csak egy számot írj, semmi mást!\\n{prompt}\"\n",
        "\n",
        "    response = llm(full_prompt, max_tokens=10)\n",
        "    assistant_response = response['choices'][0]['text'].strip()\n",
        "    return assistant_response\n",
        "\n",
        "def add_analysis(example):\n",
        "    input_text = example['input']\n",
        "    instruction_text = example['instruction']\n",
        "    response_text = example['response']\n",
        "    analysis = analyze_interaction(input_text, response_text, instruction_text)\n",
        "    example['analize'] = analysis\n",
        "    return example\n",
        "\n",
        "def process_chunk(chunk, chunk_id, num_chunks, chunk_dir):\n",
        "    print(f\"Processing chunk {chunk_id + 1}/{num_chunks}...\")\n",
        "    chunk = chunk.map(add_analysis)\n",
        "    chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "    with open(chunk_file, 'w', encoding='utf-8') as f:\n",
        "        for item in chunk:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    print(f\"Chunk {chunk_id} saved to {chunk_file}.\")\n",
        "    print(f\"Progress: {((chunk_id + 1) / num_chunks) * 100:.2f}%\")\n",
        "\n",
        "def get_last_processed_chunk(chunk_dir):\n",
        "    chunk_files = [f for f in os.listdir(chunk_dir) if f.startswith('chunk_') and f.endswith('.jsonl')]\n",
        "    if not chunk_files:\n",
        "        return -1\n",
        "    chunk_ids = [int(f.split('_')[1].split('.')[0]) for f in chunk_files]\n",
        "    return max(chunk_ids)\n",
        "\n",
        "# Ellenőrizzük az utolsó feldolgozott chunk-ot\n",
        "chunk_dir = 'chunks3'\n",
        "if not os.path.exists(chunk_dir):\n",
        "    os.makedirs(chunk_dir)\n",
        "last_processed_chunk = get_last_processed_chunk(chunk_dir)\n",
        "\n",
        "# Adatok 5000 soros darabokra bontása és feldolgozása\n",
        "chunk_size = 5000\n",
        "num_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size\n",
        "\n",
        "# Összes feldolgozási idő mérése\n",
        "start_time = time.time()\n",
        "\n",
        "for chunk_id in range(last_processed_chunk + 1, num_chunks):\n",
        "    start_idx = chunk_id * chunk_size\n",
        "    end_idx = min(start_idx + chunk_size, len(dataset['train']))\n",
        "    chunk = dataset['train'].select(range(start_idx, end_idx))\n",
        "    process_chunk(chunk, chunk_id, num_chunks, chunk_dir)\n",
        "\n",
        "# Az összesített eredmények összegyűjtése\n",
        "def aggregate_results(num_chunks, chunk_dir):\n",
        "    all_data = []\n",
        "    for chunk_id in range(num_chunks):\n",
        "        chunk_file = os.path.join(chunk_dir, f'chunk_{chunk_id}.jsonl')\n",
        "        if os.path.exists(chunk_file):\n",
        "            with open(chunk_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    all_data.append(json.loads(line))\n",
        "    return all_data\n",
        "\n",
        "all_results = aggregate_results(num_chunks, chunk_dir)\n",
        "\n",
        "# Összesített eredmények mentése\n",
        "with open('data_with_analysis.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in all_results:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"All chunks have been processed and aggregated in {total_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "id": "Z6LWOGT8znuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adatelemzés"
      ],
      "metadata": {
        "id": "1dgYf8KxLF8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Betöltjük a data_with_analysis.jsonl fájlt\n",
        "input_file = 'data_with_analysis.jsonl'\n",
        "output_file = 'filtered_data_with_analysis_8-10.jsonl'\n",
        "\n",
        "filtered_data = []\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    for line in infile:\n",
        "        data = json.loads(line)\n",
        "        try:\n",
        "            # Ellenőrizzük az értékelés értékét, és ha 8 vagy nagyobb, megtartjuk a sort\n",
        "            if int(data['analize']) >= 8:\n",
        "                filtered_data.append(data)\n",
        "        except ValueError:\n",
        "            # Ha az értékelés nem konvertálható számmá, kihagyjuk a sort\n",
        "            continue\n",
        "\n",
        "# Az eredményeket egy új fájlba mentjük\n",
        "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "    for item in filtered_data:\n",
        "        outfile.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"Filtered data saved to {output_file}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9nqsfNmictY",
        "outputId": "47689f93-3eb5-4897-cec7-6419cfeb4902"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data saved to filtered_data_with_analysis_8-10.jsonl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# A jsonl fájl olvasása\n",
        "input_file = 'data_with_analysis.jsonl'\n",
        "\n",
        "# Külön fájlok meghatározása az 'analize' oszlop értékei szerint\n",
        "output_files = {\n",
        "    '1': 'output_1.jsonl',\n",
        "    '2': 'output_2.jsonl',\n",
        "    '3': 'output_3.jsonl',\n",
        "    '4': 'output_4.jsonl',\n",
        "    '5': 'output_5.jsonl',\n",
        "    '6': 'output_6.jsonl',\n",
        "    '7': 'output_7.jsonl',\n",
        "    '8': 'output_8.jsonl',\n",
        "    '9': 'output_9.jsonl',\n",
        "    '10': 'output_10.jsonl',\n",
        "    'non_numeric': 'output_non_numeric.jsonl'\n",
        "}\n",
        "\n",
        "# Üres fájlok létrehozása és megnyitása írásra\n",
        "output_handlers = {key: open(output_files[key], 'w') for key in output_files}\n",
        "\n",
        "with open(input_file, 'r') as infile:\n",
        "    for line in infile:\n",
        "        data = json.loads(line)\n",
        "        analize_value = str(data.get('analize', 'non_numeric'))\n",
        "\n",
        "        # Ellenőrzés, hogy az 'analize' érték numerikus-e és az 1-10 tartományba esik-e\n",
        "        if analize_value.isdigit() and analize_value in output_handlers:\n",
        "            output_handlers[analize_value].write(line)\n",
        "        else:\n",
        "            output_handlers['non_numeric'].write(line)\n",
        "\n",
        "# Fájlok bezárása\n",
        "for handler in output_handlers.values():\n",
        "    handler.close()\n"
      ],
      "metadata": {
        "id": "VqN_gsr-t-35"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}