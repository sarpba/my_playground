{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Ez a munkalap egy audió file daraboló, ami a feltöltött hanganyagot mondatokra, rövidebb szövegrészletekre bontja."
      ],
      "metadata": {
        "id": "s_vpAqTVO_36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Függőségek telepítése**"
      ],
      "metadata": {
        "id": "LhluAd9gM4Gi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUbARcKMjTUY"
      },
      "outputs": [],
      "source": [
        "# Szükséges könyvtárak telepítése\n",
        "!pip install moviepy pandas\n",
        "!pip install faster-whisper\n",
        "!pip install srt\n",
        "!pip install pydub\n",
        "# Telepítsd az ffmpeg-et\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MP3 fileok és hozzá tartozó whisper-large-v2-vel készített str fileok feltöltése**"
      ],
      "metadata": {
        "id": "4zLdOAp3Oq8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Mappa létrehozása, ha még nem létezik\n",
        "os.makedirs('/content/files', exist_ok=True)\n",
        "\n",
        "# Fájlok feltöltése\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Fájlok áthelyezése a /content/files mappába\n",
        "for file_name in uploaded.keys():\n",
        "    os.rename(file_name, f'/content/files/{file_name}')\n",
        "\n",
        "print(\"Fájlok sikeresen feltöltve és áthelyezve a /content/files mappába.\")"
      ],
      "metadata": {
        "id": "DXsLpYBdF9kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Felirat file(ok) készítése (ha töltöttél fel az MP3-ak mellé, akkor kihagyható)"
      ],
      "metadata": {
        "id": "o8SIgSh4Wis-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import srt\n",
        "import torch\n",
        "from faster_whisper import WhisperModel\n",
        "from datetime import timedelta\n",
        "\n",
        "# Inicializáljuk a modellt\n",
        "model = WhisperModel(\"large-v2\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Beállítjuk a könyvtárat\n",
        "directory = \"/content/files\"\n",
        "\n",
        "# Létrehozzuk az SRT fájlokat\n",
        "def seconds_to_timedelta(seconds):\n",
        "    return timedelta(seconds=seconds)\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".mp3\") or filename.endswith(\".wav\") or filename.endswith(\".m4a\"):  # kiterjesztés alapján szűrünk\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        print(f\"Processing {file_path}\")\n",
        "\n",
        "        # Beolvasás és transzkripció\n",
        "        segments, info = model.transcribe(file_path, language=\"hu\")\n",
        "\n",
        "        # SRT fájl létrehozása\n",
        "        srt_filename = os.path.splitext(file_path)[0] + \".srt\"\n",
        "        with open(srt_filename, \"w\", encoding=\"utf-8\") as srt_file:\n",
        "            subs = []\n",
        "            for i, segment in enumerate(segments):\n",
        "                start = seconds_to_timedelta(segment.start)\n",
        "                end = seconds_to_timedelta(segment.end)\n",
        "                text = segment.text\n",
        "                subs.append(srt.Subtitle(index=i, start=start, end=end, content=text))\n",
        "            srt_file.write(srt.compose(subs))\n",
        "\n",
        "print(\"Transcription and SRT generation completed.\")\n"
      ],
      "metadata": {
        "id": "zonhTg0LTwm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A files mappába feltöltött mp3+str párosok darabolása"
      ],
      "metadata": {
        "id": "lWQiI3DGMvJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# SRT fájl beolvasása\n",
        "def parse_srt(srt_path):\n",
        "    with open(srt_path, 'r', encoding='utf-8') as file:\n",
        "        srt_data = file.read()\n",
        "\n",
        "    pattern = re.compile(r'(\\d+)\\s+(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\s+(.+?)\\s*(?=\\d+\\s+\\d{2}:\\d{2}:\\d{2},\\d{3} -->|\\Z)', re.S)\n",
        "    matches = pattern.findall(srt_data)\n",
        "\n",
        "    srt_entries = []\n",
        "    for match in matches:\n",
        "        start_time = match[1].replace(',', '.')\n",
        "        end_time = match[2].replace(',', '.')\n",
        "        text = match[3].strip()\n",
        "        srt_entries.append((start_time, end_time, text))\n",
        "\n",
        "    return pd.DataFrame(srt_entries, columns=['start', 'end', 'text'])\n",
        "\n",
        "# Időbélyeg konvertálása másodpercekre\n",
        "def time_to_seconds(time_str):\n",
        "    h, m, s = map(float, time_str.split(':'))\n",
        "    return h * 3600 + m * 60 + s\n",
        "\n",
        "# Hangfájl feldarabolása\n",
        "def split_audio(audio_path, srt_df, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Az eredeti fájl nevének kinyerése kiterjesztés nélkül\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "    for index, row in srt_df.iterrows():\n",
        "        start_time = time_to_seconds(row['start'])\n",
        "        end_time = time_to_seconds(row['end'])\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(f\"Processing clip {index + 1} from {start_time} to {end_time}\")\n",
        "\n",
        "        output_file = os.path.join(output_folder, f\"{base_name}_{index + 1}.mp3\")\n",
        "\n",
        "        # FFmpeg parancs futtatása\n",
        "        command = [\n",
        "            'ffmpeg', '-y', '-i', audio_path, '-ss', str(start_time), '-t', str(duration),\n",
        "            '-acodec', 'copy', output_file\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "       # print(f\"Command: {' '.join(command)}\")\n",
        "       # print(f\"stdout: {result.stdout.decode('utf-8')}\")\n",
        "       # print(f\"stderr: {result.stderr.decode('utf-8')}\")\n",
        "       # print(f\"Saved clip to {output_file}\")\n",
        "\n",
        "# Fő program\n",
        "def process_directory(directory_path, output_folder):\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith('.mp3'):\n",
        "            audio_path = os.path.join(directory_path, file_name)\n",
        "            srt_path = os.path.splitext(audio_path)[0] + '.srt'\n",
        "            if os.path.exists(srt_path):\n",
        "                print(f\"Processing pair: {audio_path} and {srt_path}\")\n",
        "                srt_df = parse_srt(srt_path)\n",
        "                split_audio(audio_path, srt_df, output_folder)\n",
        "            else:\n",
        "                print(f\"No matching SRT file for {audio_path}\")\n",
        "\n",
        "# Add meg a könyvtár pontos útvonalát\n",
        "directory_path = '/content/files'\n",
        "output_folder = '/content/splits'\n",
        "\n",
        "process_directory(directory_path, output_folder)"
      ],
      "metadata": {
        "id": "e-CpFmsE1iYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Initialize the model\n",
        "model_size = \"large-v2\"  # You can choose other model sizes as needed\n",
        "model = WhisperModel(model_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Directory containing audio files\n",
        "input_dir = \"/content/splits\"\n",
        "\n",
        "# Process each file in the directory\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".wav\") or filename.endswith(\".mp3\"):  # Assuming audio files are in .wav or .mp3 format\n",
        "        file_path = os.path.join(input_dir, filename)\n",
        "        segments, _ = model.transcribe(file_path, language=\"hu\")  # Set language to Hungarian (hu)\n",
        "\n",
        "        # Create the corresponding txt file\n",
        "        txt_filename = filename.rsplit(\".\", 1)[0] + \".txt\"\n",
        "        txt_filepath = os.path.join(input_dir, txt_filename)\n",
        "\n",
        "        with open(txt_filepath, \"w\") as f:\n",
        "            for segment in segments:\n",
        "                f.write(segment.text + \"\\n\")\n",
        "\n",
        "        print(f\"Transcription for {filename} saved to {txt_filename}\")\n",
        "\n",
        "print(\"Transcription completed for all files.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iV-FUsRCc9p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Mappák létrehozása\n",
        "os.makedirs('/content/LJSpeech/wavs', exist_ok=True)\n",
        "os.makedirs('/content/LJSpeech/', exist_ok=True)\n",
        "\n",
        "# Fájlok beolvasása\n",
        "splits_path = '/content/splits'\n",
        "wav_path = '/content/LJSpeech/wavs'\n",
        "metadata_path = '/content/LJSpeech'\n",
        "\n",
        "metadata = []\n",
        "\n",
        "for root, dirs, files in os.walk(splits_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.mp3'):\n",
        "            mp3_file = os.path.join(root, file)\n",
        "            txt_file = os.path.join(root, file.replace('.mp3', '.txt'))\n",
        "\n",
        "            if os.path.exists(txt_file):\n",
        "                # Olvassuk be a szöveget\n",
        "                with open(txt_file, 'r', encoding='utf-8') as f:\n",
        "                    text = f.read().strip()\n",
        "\n",
        "                # MP3 konvertálása WAV formátumra\n",
        "                audio = AudioSegment.from_mp3(mp3_file)\n",
        "                wav_filename = f\"LJ{str(len(metadata) + 1).zfill(3)}-{str(len(metadata) + 1).zfill(4)}.wav\"\n",
        "                wav_filepath = os.path.join(wav_path, wav_filename)\n",
        "                audio.export(wav_filepath, format='wav')\n",
        "\n",
        "                # Metadata frissítése\n",
        "                metadata.append([wav_filename, text])\n",
        "\n",
        "# Metadata.csv létrehozása\n",
        "metadata_df = pd.DataFrame(metadata, columns=['file', 'text'])\n",
        "metadata_df.to_csv('/content/LJSpeech/metadata.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "k5hAvXdTfmlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Az elkészült darabok letöltése."
      ],
      "metadata": {
        "id": "hkS8SSIVMnkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# A tömörítendő mappa elérési útja\n",
        "folder_to_zip = '/content/LJSpeech'\n",
        "# A tömörített fájl neve\n",
        "output_filename = 'LJSpeech.zip'\n",
        "\n",
        "# Tömörítés\n",
        "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "\n",
        "# Ellenőrizzük, hogy a fájl létezik-e\n",
        "if os.path.exists(output_filename):\n",
        "    print(f'{output_filename} sikeresen létrehozva.')\n",
        "\n",
        "# Letöltés\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "WGOD_BYUMmJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Munbkakörnyezet takarítása!"
      ],
      "metadata": {
        "id": "WZdXfrDPOM6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# A törlendő mappák és fájlok elérési útjai\n",
        "folders_to_delete = ['/content/files', '/content/splits', '/content/LJSpeech']\n",
        "file_to_delete = '/content/splits.zip'\n",
        "\n",
        "# Mappák törlése\n",
        "for folder in folders_to_delete:\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "        print(f'{folder} sikeresen törölve.')\n",
        "    else:\n",
        "        print(f'{folder} nem található.')\n",
        "\n",
        "# Fájl törlése\n",
        "if os.path.exists(file_to_delete):\n",
        "    os.remove(file_to_delete)\n",
        "    print(f'{file_to_delete} sikeresen törölve.')\n",
        "else:\n",
        "    print(f'{file_to_delete} nem található.')"
      ],
      "metadata": {
        "id": "hs8Z2_6-ORS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}